{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "- Daniel Fichthorn: \n",
    "- Evan Asti:  \n",
    "- Saidazim Saidov: \n",
    "- Mulan Zhou: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the relationship between opioids incedance (overdoses, hospitalizations, check into rehab) in Portland and housing prices as well as average time spent on zillow before being sold change in 2020 to 2021?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our topic is on housing prices & drug usage in Portland, specifically before and after the 2020 Oregon Ballot Measure 110 was passed. Measure 110 reduced the penalties for drug possession for small amounts of controlled substances, reducing it from a class A misdemeanor to class E. We want to study how this may have affected the general population of Portland's access to housing, and if drug usage was related during this time period. By 2024 measure 110 was largely repealed.<a name = \"Drug_Decriminalization\">[</a><sup>4</sup>](#Drug_Decriminalization_ref)\n",
    "\n",
    "A number of studies were conducted about this time period, all which studied the effect of drug decriminalization in Portland in specific categories. \n",
    "\n",
    "One study found that housing instability and opioid related harms often rise together, especially in areas facing rapid policy shifts. Using cross-sectional survey data from unstably housed individuals with a history of drug use, the study identified key demographic and behavioral factors associated with access to housing assistance, including frequency of opioid use and community supervision status. The study stated that, \"Participants were recruited [...] with partner agencies that provide supportive services [...] direct outreach by the study team to homeless\"<a name=\"cite_ref-1\"></a>[<sup>2</sup>](#cite_note-1). While this research focuses on individuals already experiencing housing instability, our study differs by examining broader population-level trends in Portland before and after the passage of Measure 110. Rather than relying on survey data, we analyze changes in housing prices alongside drug usage indicators to explore whether decriminalization coincided with shifts in housing accessibility and market conditions. This allows us to investigate potential associations at a city-wide level and assess how policy changes may have impacted both housing dynamics and drug use simultaneously over time.\n",
    "\n",
    "Another study examined whether Oregon’s 2021 decriminalization of drug possession was linked to changes in overdose mortality while accounting for the spread of fentanyl in the unregulated drug market. The study found that “decriminalization of drug possession was not associated with an increase in fatal drug overdose rates in Oregon in the 2 years after its enactment” once fentanyl was considered as a confounding factor<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2). The authors emphasized that fentanyl is “the principal driver of the overdose mortality epidemic in the US,” suggesting that increases in overdose deaths cannot be attributed to Measure 110 alone. While this research focuses on overdose mortality rather than housing outcomes, it is still relevant to our study because it highlights the importance of accounting for external factors when evaluating the effects of drug policy changes. Our research builds on this idea by examining housing prices and drug usage trends in Portland before and after Measure 110 to better understand how policy changes may have impacted the broader community.\n",
    "\n",
    "How does the relationship between opioids incedance (overdoses, hospitalizations, check into rehab) in Portland and housing prices as well as average time spent on zillow before being sold change in 2020 to 2021.\n",
    "\n",
    "\n",
    "A DID design with time fixed effects from researchers at The Peoples Republic of China finds that measure 110 lowered residential real estate value by more than 1%.<a name = \"110_Econ_article\">[</a><sup>3</sup>](#110_Econ_article_ref) Furthermore, they find that the effects are statsisticly significant, even at the 1% value. The research design for this seems relativly robust, with the authors showing other methods that give similar results. This gives us hope that our analysis will find some interesting correlational patterns, and leads directly into our hypothesis.\n",
    "\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Chung, Esther O et al. “Housing assistance among people who are unstably housed and use drugs in Oregon: a cross-sectional study.” BMC public health vol. 25,1 740. 23 Feb. 2025, doi:10.1186/s12889-025-21925-y.\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Zoorob, Michael J et al. “Drug Decriminalization, Fentanyl, and Fatal Overdoses in Oregon.” JAMA network open vol. 7,9 e2431612. 3 Sep. 2024, doi:10.1001/jamanetworkopen.2024.31612.\n",
    "3. <a name=\"110_Econ_article\"></a>[^](#110_Econ_article_ref) M Joukov, Artem. \"Can You Take Me Higher? No. 110, Drug Decriminalization, and Residential Real Estate Prices.\" Drug Decriminalization, and Residential Real Estate Prices (October 28, 2024) (2024).\n",
    "4. <a name=\"Drug_Decriminalization\"></a>[^](#Drug_Decriminalization_ref) Staudt, Sarah. “Oregon Shouldn’t Go Backwards on Drug Decriminalization.” Www.prisonpolicy.org, 15 Feb. 2024, www.prisonpolicy.org/blog/2024/02/15/oregon-110/.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that there will be a negative correlation between opioid-related incidents and both median housing prices and market velocity (average time spent on Zillow) in Portland between 2020 and 2021. Specifically, as opioid overdoses and hospitalizations increased in certain zip codes, we predict that home sale prices in those areas decreased relative to the city average, while the \"days on Zillow\" significantly increased.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "#%pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    {\n",
    "        'url': 'https://raw.githubusercontent.com/COGS108/Group008_WI26/master/data/00-raw/annual_by_county_death-2026-01-08.csv', 'filename': 'annual_by_county_death-2026-01-08.csv'\n",
    "    }\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oregon Overdose Death Data\n",
    "\n",
    "https://oregoninjurydata.shinyapps.io/overdose/#county3\n",
    "\n",
    "This dataset is rather straigntforward. It has information for opiod related deaths by county for all of Oregon from 210 to 2024. This data is already rather clean, so the only real thing to do here is to change the columns from strings into a more appropriate type so that we can use our analytic tools on them. Here the count collumn indicates the amount of people who died due to opioid related incidents for the corresponding county and year. The rate column shows the amount of deaths per one hundred thousand people in the county.\n",
    "\n",
    "The only possible concern we can see with this data is that this is that according to the Oregon Health Authority \"Not all deaths are certified by a medical examiner in Oregon, therefore not all deaths will have a toxicology test performed.\" This means that this data likely undrepresents the true amount of opioid related deaths in the state. There is (to our knowledge) no way to account for this properly, so we will have to keep that in mind when we begin our more formal analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the usual packages and load the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "oregon_deaths_df = pd.read_csv('data/00-raw/annual_by_county_death-2026-01-08.csv')\n",
    "\n",
    "#Lets also check for missing values\n",
    "oregon_deaths_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the data and check for missing values\n",
    "oregon_deaths_df.head(10)\n",
    "\n",
    "# We see that we will need to map Count and Rate to Numerical objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will map the low number counts 'Counts between 1 and 4' to its average rounded down (2) , and just set the rate to missing for now. We will drop these later but we believe we may want those rows for analysis later\n",
    "oregon_deaths_df = oregon_deaths_df.replace({\n",
    "    'Count between 1 and 4.': 2,\n",
    "    'Rate not reportable. Count between 1 and 4.': np.nan\n",
    "})\n",
    "\n",
    "#Now make Count and Rate into numeric variables\n",
    "oregon_deaths_df['Count'] = pd.to_numeric(oregon_deaths_df['Count'])\n",
    "oregon_deaths_df['Rate (per 100K)'] = pd.to_numeric(oregon_deaths_df['Rate (per 100K)'])\n",
    "\n",
    "#Then Check the dtypes\n",
    "oregon_deaths_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally lets investigate the data once again\n",
    "oregon_deaths_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks allright to me - lets move on to check for outliers and some basic descriptive statistics\n",
    "oregon_deaths_df[['Count', 'Rate (per 100K)']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see at least one clear outlier from our head call 2 cells above - lets check up on that entry. A quick google search seems to confirm that these numbers are accurate. As the max of count is remarkably similar (same order of magnitude) we are inclined to believe that all of this data makes sense and the high values are abnormal but not due to human error. Here is an article from 2024 that supports this position: https://multco.us/news/multnomah-county-releases-2023-domicile-unknown-report-homeless-deaths.\n",
    "Note that the standard deviations reported here are incorrect as these calculations are not clustered properly, so do not be alarmed by its large value. The other statistics should all be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CSV with missing values under interim \n",
    "oregon_deaths_df.to_csv('data/01-interim/annual_by_county_death_nas.csv', index=False)\n",
    "\n",
    "# make a copy where we drop the missing value rows completely and save under processed\n",
    "oregon_deaths_df_clean = oregon_deaths_df.dropna(subset=['Rate (per 100K)'])\n",
    "oregon_deaths_df_clean.to_csv('data/02-processed/annual_by_county_death_clean.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of Different Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> Example of how to use the checkbox, and also of how you can put in a short paragraph that discusses the way this checklist item affects your project.  Remove this paragraph and the X in the checkbox before you fill this out for your project\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    ">Drug incidence data is often a proxy for policing intensity rather than actual drug usage rates. Low-income neighborhoods or areas with more public transit may show higher drug incidence in police records because of increased surveillance, not necessarily because drug use is higher than high-income areas.\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    ">We should ensure that you are using aggregated data rather than individual data.\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    ">Our project involves \"protected group status\" implicitly through geographic proxies (zip codes). There is a risk that findings could be used to further stigmatize specific Portland neighborhoods or justify \"redlining-like\" behavior in real estate. We should attempt to discuss the socioeconomic confounding variables (like poverty rates or historical disinvestment) that impact both housing prices and public health outcomes.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    ">While the datasets are public, we will maintain a secure workflow to ensure data security. All data will be processed and stored in a private Github repository. Only team members and course staff will have access.\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    ">Our team will retain the data only for the duration of the Winter 2026 quarter. Once we have received our final grade, we will delete all local copies of the dataset and archive the Github repository.\n",
    "\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    ">We are aware of potential confounds related to race, financial background, and mental illness. All of these are well documented elements in Measure 110's history, and we believe that the model results will be generalized to be fair with respect to different groups, since we will not be concentrating on any of these aspects in our models. Groups could be revisited in our conclusion if a weak correlation is drawn.\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    ">Additional metrics plan to be substantiated by the background given, and we have also uncovered papers which have good data models that we want to replicate. By replicating these models, we can wrangle the data to work with other datasets of ours, and begin to explore and analyze data further. Optimizing our defined metrics directly is related to consulting outside sources, and we are prepared to cite these sources appropriately.\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    ">Similar to D.2, if we find that our model accentuates more complex relationships in race for instance, we would want a disclaimer of what our data looks at and the connection it aims to establish, and what the data does not suggest. We want to ensure our data is communicated in a way that is indicative of what we wanted to establish a correlational between, and do not want our data used in samples that to make correlations that it was not intended for. If users are excessively harmed, we will act accordingly to have our data be more selective to public. This also doubles as an answer for E.4.\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Timely Communication and do so in a respectful manner\n",
    "* Be Ethical with all our work & conversations\n",
    "* Respectable to everyone in the group "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/18  | 6 PM  | Clean data; Import & Wrangle Data (Portland Drug Usage & Housing in Portland) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/25  | 6 PM  | Finalize wrangling/EDA; Begin Analysis | Discuss/edit Analysis; Complete project check-in |\n",
    "| 3/13  | 6 PM  | Complete analysis; Draft results/conclusion/discussion (Wasp)| Discuss/edit full project; Finalize |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
